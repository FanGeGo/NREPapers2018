# Relation Extraction in 2018

## COLING 2018

1. **Adversarial Multi-lingual Neural Relation Extraction**
    _Xiaozhi Wang, Xu Han, Yankai Lin, Zhiyuan Liu and Maosong Sun._
    COLING 2018
    [paper](http://aclweb.org/anthology/C18-1099) [code](https://github.com/thunlp/AMNRE)
    >Existing models cannot well capture the consistency and diversity of relation patterns in different languages. To address these issues, we propose an adversarial multi-lingual neural relation extraction (AMNRE) model, which builds both consistent and individual representations for each sentence to consider the consistency and diversity among languages. Further, we adopt an adversarial training strategy to ensure those consistent sentence representations could effectively extract the language-consistent relation patterns.

2. **Cooperative Denoising for Distantly Supervised Relation Extraction**
    _Kai Lei, Daoyuan Chen, Yaliang Li, Nan Du, Min Yang, Wei Fan and Ying Shen._
    COLING 2018
    [paper](http://aclweb.org/anthology/C18-1036)

    DSRE: Learning in the noise.
    >we propose a novel neural relation extraction framework with bi-directional knowledge distillation to cooperatively use different information sources and alleviate the noisy label problem in distantly supervised relation extraction.

3. **Exploratory Neural Relation Classification for Domain Knowledge Acquisition**
    _Yan Fan, Chengyu Wang and Xiaofeng He._
    COLING 2018
    [paper](http://aclweb.org/anthology/C18-1192)

    Exploratory Relation Classification (ERC): **NRC + new task**!
    >In this paper, we propose the task of ERC to address the problem of domain-specific knowledge acquisition. We propose a DSNN model to address the task, consisting of three modules, an integrated base neural network for relation classification, a similarity-based clustering algorithm ssCRP to generate new relations and constrained relation prediction process with the purpose of populating new relations.

4. **Multilevel Heuristics for Rationale-Based Entity Relation Classification in Sentences**
    _Shiou Tian Hsu, Mandar Chaudhary and Nagiza Samatova._
    COLING 2018
    [paper](http://aclweb.org/anthology/C18-1098)

    NRC + rationale interpretability **NRC + new task**!

    >In this paper, we have proposed an improved rationale-based model for entity relation classification. In our model, besides context word information, we also moderate rationale generation with multiple heuristics computed from different text level features. 

5. **Neural Relation Classification with Text Descriptions**
    _Feiliang Ren, Di Zhou, Zhihui Liu, Yongcheng Li, Rongsheng Zhao, Yongkang Liu and Xiaobo Liang._
    COLING 2018
    [paper](http://aclweb.org/anthology/C18-1100)

    NRC

    >In this paper, we propose DesRC, a new neural relation classification method which integrates entities text descriptions into deep neural networks models. We design a two-level attention mechanism to select the most useful information from the ”intra-sentence” aspect and the ”cross-sentence” aspect. Besides, the adversarial training method is also used to further improve the classification performance.

6. **Word-Level Loss Extensions for Neural Temporal Relation Classification**
    _Artuur Leeuwenberg and Marie-Francine Moens._
    COLING 2018
    [paper](http://aclweb.org/anthology/C18-1291)

    Temporal Relation Classification

    >In this work, we extend our classification model’s task loss with an unsupervised auxiliary loss on the word-embedding level of the model.
